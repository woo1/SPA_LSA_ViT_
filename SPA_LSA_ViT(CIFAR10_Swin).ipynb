{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPA_LSA_ViT(CIFAR10_Swin).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Official Code : https://github.com/aanna0701/SPT_LSA_ViT <br>\n",
        "This code is to train CIFAR10 dataset with Swin Transformer. <br>\n",
        "If you need another transformer model, you should add some more sources."
      ],
      "metadata": {
        "id": "NXtZPIHRsLV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install einops\n",
        "!pip install colorama\n",
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJgiz4rMsc1y",
        "outputId": "9e127c2b-754c-498f-c230-e088d617c3ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.0\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def mixup_data(x, y, args):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if args.alpha > 0:\n",
        "        lam = np.random.beta(args.alpha, args.alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    \n",
        "    index = torch.randperm(batch_size).cuda()\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def cutmix_data(x, y, args):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if args.beta > 0:\n",
        "        lam = np.random.beta(args.beta, args.beta)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    \n",
        "    index = torch.randperm(batch_size).cuda()\n",
        "\n",
        "    y_a, y_b = y, y[index]\n",
        "\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
        "    x_sliced = x[index, :, bbx1:bbx2, bby1:bby2]\n",
        "    # adjust lambda to exactly match pixel ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
        "    \n",
        "    return [bbx1, bby1, bbx2, bby2 ], y_a, y_b, lam, x_sliced\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
      ],
      "metadata": {
        "id": "HOPFRscTa6iU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thanks to rwightman's timm package\n",
        "# github.com:rwightman/pytorch-image-models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    \"\"\"\n",
        "    NLL loss with label smoothing.\n",
        "    \"\"\"\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        \"\"\"\n",
        "        Constructor for the LabelSmoothing module.\n",
        "        :param smoothing: label smoothing factor\n",
        "        \"\"\"\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "        assert smoothing < 1.0\n",
        "        self.smoothing = smoothing\n",
        "        self.confidence = 1. - smoothing\n",
        "\n",
        "    def _compute_losses(self, x, target):\n",
        "        log_prob = F.log_softmax(x, dim=-1)\n",
        "        nll_loss = -log_prob.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -log_prob.mean(dim=-1)\n",
        "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        return self._compute_losses(x, target).mean()"
      ],
      "metadata": {
        "id": "m9E3-iCnbR2O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) 2015-present, Facebook, Inc.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the CC-by-NC license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from collections.abc import Mapping, Sequence\n",
        "\n",
        "\n",
        "class RASampler(torch.utils.data.Sampler):\n",
        "    \"\"\"\n",
        "    Batch Sampler with Repeated Augmentations (RA)\n",
        "    - dataset_len: original length of the dataset\n",
        "    - batch_size\n",
        "    - repetitions: instances per image\n",
        "    - len_factor: multiplicative factor for epoch size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_len, batch_size, repetitions=1, len_factor=3.0, shuffle=False, drop_last=False):\n",
        "        self.dataset_len = dataset_len\n",
        "        self.batch_size = batch_size\n",
        "        self.repetitions = repetitions\n",
        "        self.len_images = int(dataset_len * len_factor)\n",
        "        self.shuffle = shuffle\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "    def shuffler(self):\n",
        "        if self.shuffle:\n",
        "            new_perm = lambda: iter(np.random.permutation(self.dataset_len))\n",
        "        else:\n",
        "            new_perm = lambda: iter(np.arange(self.dataset_len))\n",
        "        shuffle = new_perm()\n",
        "        while True:\n",
        "            try:\n",
        "                index = next(shuffle)\n",
        "            except StopIteration:\n",
        "                shuffle = new_perm()\n",
        "                index = next(shuffle)\n",
        "            for repetition in range(self.repetitions):\n",
        "                yield index\n",
        "\n",
        "    def __iter__(self):\n",
        "        shuffle = iter(self.shuffler())\n",
        "        seen = 0\n",
        "        batch = []\n",
        "        for _ in range(self.len_images):\n",
        "            index = next(shuffle)\n",
        "            batch.append(index)\n",
        "            if len(batch) == self.batch_size:\n",
        "                yield batch\n",
        "                batch = []\n",
        "        if batch and not self.drop_last:\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.drop_last:\n",
        "            return self.len_images // self.batch_size\n",
        "        else:\n",
        "            return (self.len_images + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "\n",
        "def list_collate(batch):\n",
        "    \"\"\"\n",
        "    Collate into a list instead of a tensor to deal with variable-sized inputs\n",
        "    \"\"\"\n",
        "    elem_type = type(batch[0])\n",
        "    if isinstance(batch[0], torch.Tensor):\n",
        "        return batch\n",
        "    elif elem_type.__module__ == 'numpy':\n",
        "        if elem_type.__name__ == 'ndarray':\n",
        "            return list_collate([torch.from_numpy(b) for b in batch])\n",
        "    elif isinstance(batch[0], Mapping):\n",
        "        return {key: list_collate([d[key] for d in batch]) for key in batch[0]}\n",
        "    elif isinstance(batch[0], Sequence):\n",
        "        transposed = zip(*batch)\n",
        "        return [list_collate(samples) for samples in transposed]\n",
        "    return default_collate(batch)"
      ],
      "metadata": {
        "id": "N1GvZhrMbXmi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "term_width = int(20)\n",
        "\n",
        "TOTAL_BAR_LENGTH = 65.\n",
        "\n",
        "def progress_bar(current, total, msg=None):\n",
        "  \n",
        "    L = []\n",
        "    if msg:\n",
        "        L.append(msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ],
      "metadata": {
        "id": "sofWEEcSbgbi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "import csv\n",
        "from genericpath import exists\n",
        "import os\n",
        "\n",
        "keys = ['T Loss', 'T Top-1', 'V Loss', 'V Top-1', 'ParameterScale']\n",
        "\n",
        "class Logger_dict():\n",
        "    def __init__(self, logger, save_path):\n",
        "        self.dict = OrderedDict()\n",
        "        self.logger = logger\n",
        "        self.savepath = save_path\n",
        "        if os.path.exists(os.path.join(self.savepath, 'log.csv')):\n",
        "            self.init_csv()\n",
        "        self.write_csv(keys)\n",
        "                \n",
        "    def update(self, key, value):\n",
        "        self.dict[key] = value\n",
        "        \n",
        "    def init_csv(self):\n",
        "        fileVariable = open(os.path.join(self.savepath, 'log.csv'), 'r+')\n",
        "        fileVariable.truncate(0)\n",
        "        fileVariable.close()\n",
        "        \n",
        "    def write_csv(self, x):\n",
        "        with open(os.path.join(self.savepath, 'log.csv'), \"a\") as outfile:\n",
        "            csvwriter = outfile\n",
        "            csvwriter = csv.writer(outfile)\n",
        "            csvwriter.writerow(x)\n",
        "        \n",
        "    def print(self):\n",
        "        i = 0\n",
        "        values = []\n",
        "        for key, value in self.dict.items():\n",
        "            print(f'{key}' +'\\t'+ f'{value}')\n",
        "            i += 1\n",
        "            values.append(value)\n",
        "        self.write_csv(values)\n",
        "        print()"
      ],
      "metadata": {
        "id": "iQEq27Itbbxt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=0, verbose=0, mode='max'):\n",
        "        self._step = 0\n",
        "        self._loss = 0.0\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.best_value = 0.0\n",
        "        if mode == 'max':\n",
        "            self.mode = 1\n",
        "        else:\n",
        "            self.mode = -1 \n",
        "\n",
        "    def validate(self, value):\n",
        "        if self._loss * self.mode >= value * self.mode:\n",
        "            self._step += 1\n",
        "            if self._step > self.patience:\n",
        "                if self.verbose:\n",
        "                    print(f'Training process is stopped early....\\n\\n')\n",
        "                return self.best_value\n",
        "        else:\n",
        "            if self.best_value * self.mode < value * self.mode:\n",
        "                self.best_value = value\n",
        "            self._step = 0\n",
        "        \n",
        "        self._loss = value\n",
        "\n",
        "        return 0\n",
        "    \n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].flatten().float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "metadata": {
        "id": "h36GwpmPcWal"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
        "    \"\"\"\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        first_cycle_steps (int): First cycle step size.\n",
        "        cycle_mult(float): Cycle steps magnification. Default: -1.\n",
        "        max_lr(float): First cycle's max learning rate. Default: 0.1.\n",
        "        min_lr(float): Min learning rate. Default: 0.001.\n",
        "        warmup_steps(int): Linear warmup step size. Default: 0.\n",
        "        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n",
        "        last_epoch (int): The index of last epoch. Default: -1.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 optimizer : torch.optim.Optimizer,\n",
        "                 first_cycle_steps : int,\n",
        "                 cycle_mult : float = 1.,\n",
        "                 max_lr : float = 0.1,\n",
        "                 min_lr : float = 0.001,\n",
        "                 warmup_steps : int = 0,\n",
        "                 gamma : float = 1.,\n",
        "                 last_epoch : int = -1\n",
        "        ):\n",
        "        assert warmup_steps < first_cycle_steps\n",
        "        \n",
        "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
        "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
        "        self.base_max_lr = max_lr # first max learning rate\n",
        "        self.max_lr = max_lr # max learning rate in the current cycle\n",
        "        self.min_lr = min_lr # min learning rate\n",
        "        self.warmup_steps = warmup_steps # warmup step size\n",
        "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
        "        \n",
        "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
        "        self.cycle = 0 # cycle count\n",
        "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
        "        \n",
        "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
        "        \n",
        "        # set learning rate min_lr\n",
        "        self.init_lr()\n",
        "    \n",
        "    def init_lr(self):\n",
        "        self.base_lrs = []\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = self.min_lr\n",
        "            self.base_lrs.append(self.min_lr)\n",
        "    \n",
        "    def get_lr(self):\n",
        "        if self.step_in_cycle == -1:\n",
        "            return self.base_lrs\n",
        "        elif self.step_in_cycle < self.warmup_steps:\n",
        "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr + (self.max_lr - base_lr) \\\n",
        "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
        "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
        "                    for base_lr in self.base_lrs]\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "            self.step_in_cycle = self.step_in_cycle + 1\n",
        "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
        "                self.cycle += 1\n",
        "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
        "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
        "        else:\n",
        "            if epoch >= self.first_cycle_steps:\n",
        "                if self.cycle_mult == 1.:\n",
        "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
        "                    self.cycle = epoch // self.first_cycle_steps\n",
        "                else:\n",
        "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
        "                    self.cycle = n\n",
        "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
        "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
        "            else:\n",
        "                self.cur_cycle_steps = self.first_cycle_steps\n",
        "                self.step_in_cycle = epoch\n",
        "                \n",
        "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
        "        self.last_epoch = math.floor(epoch)\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "def build_scheduler(args, optimizer, n_iter_per_epoch):\n",
        "    num_steps = int(args.epochs * n_iter_per_epoch)\n",
        "    warmup_steps = int(args.warmup * n_iter_per_epoch)\n",
        "\n",
        "    lr_scheduler = CosineAnnealingWarmupRestarts(\n",
        "        optimizer,\n",
        "        first_cycle_steps=num_steps,\n",
        "        cycle_mult=1.,\n",
        "        max_lr = args.lr,\n",
        "        min_lr = 1e-6,\n",
        "        warmup_steps=warmup_steps\n",
        "        )\n",
        "    return lr_scheduler\n"
      ],
      "metadata": {
        "id": "IsZ6JnaPcj94"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from colorama import Fore, Style\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "def datainfo(logger, args):\n",
        "    if args.dataset == 'CIFAR10':\n",
        "        print(Fore.YELLOW+'*'*80)\n",
        "        logger.debug('CIFAR10')\n",
        "        print('*'*80 + Style.RESET_ALL)\n",
        "        n_classes = 10\n",
        "        img_mean, img_std = (0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)\n",
        "        img_size = 32        \n",
        "        \n",
        "    elif args.dataset == 'CIFAR100':\n",
        "        print(Fore.YELLOW+'*'*80)\n",
        "        logger.debug('CIFAR100')\n",
        "        print('*'*80 + Style.RESET_ALL)\n",
        "        n_classes = 100\n",
        "        img_mean, img_std = (0.5070, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762) \n",
        "        img_size = 32        \n",
        "        \n",
        "    elif args.dataset == 'SVHN':\n",
        "        print(Fore.YELLOW+'*'*80)\n",
        "        logger.debug('SVHN')\n",
        "        print('*'*80 + Style.RESET_ALL)\n",
        "        n_classes = 10\n",
        "        img_mean, img_std = (0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970) \n",
        "        img_size = 32\n",
        "        \n",
        "    elif args.dataset == 'T-IMNET':\n",
        "        print(Fore.YELLOW+'*'*80)\n",
        "        logger.debug('T-IMNET')\n",
        "        print('*'*80 + Style.RESET_ALL)\n",
        "        n_classes = 200\n",
        "        img_mean, img_std = (0.4802, 0.4481, 0.3975), (0.2770, 0.2691, 0.2821)\n",
        "        img_size = 64\n",
        "        \n",
        "    data_info = dict()\n",
        "    data_info['n_classes'] = n_classes\n",
        "    data_info['stat'] = (img_mean, img_std)\n",
        "    data_info['img_size'] = img_size\n",
        "    \n",
        "    return data_info\n",
        "\n",
        "def dataload(args, augmentations, normalize, data_info):\n",
        "    if args.dataset == 'CIFAR10':\n",
        "        train_dataset = datasets.CIFAR10(\n",
        "            root=args.data_path, train=True, download=True, transform=augmentations)\n",
        "        val_dataset = datasets.CIFAR10(\n",
        "            root=args.data_path, train=False, download=False, transform=transforms.Compose([\n",
        "            transforms.Resize(data_info['img_size']),\n",
        "            transforms.ToTensor(),\n",
        "            *normalize]))\n",
        "        \n",
        "    elif args.dataset == 'CIFAR100':\n",
        "\n",
        "        train_dataset = datasets.CIFAR100(\n",
        "            root=args.data_path, train=True, download=True, transform=augmentations)\n",
        "        val_dataset = datasets.CIFAR100(\n",
        "            root=args.data_path, train=False, download=False, transform=transforms.Compose([\n",
        "            transforms.Resize(data_info['img_size']),\n",
        "            transforms.ToTensor(),\n",
        "            *normalize]))\n",
        "        \n",
        "    elif args.dataset == 'SVHN':\n",
        "\n",
        "        train_dataset = datasets.SVHN(\n",
        "            root=args.data_path, split='train', download=True, transform=augmentations)\n",
        "        val_dataset = datasets.SVHN(\n",
        "            root=args.data_path, split='test', download=True, transform=transforms.Compose([\n",
        "            transforms.Resize(data_info['img_size']),\n",
        "            transforms.ToTensor(),\n",
        "            *normalize]))\n",
        "        \n",
        "    elif args.dataset == 'T-IMNET':\n",
        "        train_dataset = datasets.ImageFolder(\n",
        "            root=os.path.join(args.data_path, 'tiny_imagenet', 'train'), transform=augmentations)\n",
        "        val_dataset = datasets.ImageFolder(\n",
        "            root=os.path.join(args.data_path, 'tiny_imagenet', 'val'), \n",
        "            transform=transforms.Compose([\n",
        "            transforms.Resize(data_info['img_size']), transforms.ToTensor(), *normalize]))\n",
        "    \n",
        "    return train_dataset, val_dataset"
      ],
      "metadata": {
        "id": "9DhWUqe5cuRM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging as log\n",
        "import torch\n",
        "from torch.nn import Module\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import logging as log\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from colorama import Fore, Style\n",
        "from torchsummary import summary\n",
        "import os\n",
        "import argparse\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)"
      ],
      "metadata": {
        "id": "eI1XPDqwtzoa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
        "    \"\"\"\n",
        "    Obtained from: github.com:rwightman/pytorch-image-models\n",
        "    Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
        "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
        "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
        "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
        "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
        "    'survival rate' as the argument.\n",
        "    \"\"\"\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor_()  # binarize\n",
        "    output = x.div(keep_prob) * random_tensor\n",
        "    return output\n",
        "\n",
        "\n",
        "class DropPath(Module):\n",
        "    \"\"\"\n",
        "    Obtained from: github.com:rwightman/pytorch-image-models\n",
        "    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)"
      ],
      "metadata": {
        "id": "cn-FlSPtsr5j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "import math\n",
        "\n",
        "class ShiftedPatchTokenization(nn.Module):\n",
        "    def __init__(self, in_dim, dim, merging_size=2, exist_class_t=False, is_pe=False):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.exist_class_t = exist_class_t\n",
        "        \n",
        "        self.patch_shifting = PatchShifting(merging_size)\n",
        "        \n",
        "        patch_dim = (in_dim*5) * (merging_size**2) \n",
        "        if exist_class_t:\n",
        "            self.class_linear = nn.Linear(in_dim, dim)\n",
        "\n",
        "        self.is_pe = is_pe\n",
        "        \n",
        "        self.merging = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = merging_size, p2 = merging_size),\n",
        "            nn.LayerNorm(patch_dim),\n",
        "            nn.Linear(patch_dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        if self.exist_class_t:\n",
        "            visual_tokens, class_token = x[:, 1:], x[:, (0,)]\n",
        "            reshaped = rearrange(visual_tokens, 'b (h w) d -> b d h w', h=int(math.sqrt(x.size(1))))\n",
        "            out_visual = self.patch_shifting(reshaped)\n",
        "            out_visual = self.merging(out_visual)\n",
        "            out_class = self.class_linear(class_token)\n",
        "            out = torch.cat([out_class, out_visual], dim=1)\n",
        "        \n",
        "        else:\n",
        "            out = x if self.is_pe else rearrange(x, 'b (h w) d -> b d h w', h=int(math.sqrt(x.size(1))))\n",
        "            out = self.patch_shifting(out)\n",
        "            out = self.merging(out)    \n",
        "        \n",
        "        return out\n",
        "        \n",
        "class PatchShifting(nn.Module):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.shift = int(patch_size * (1/2))\n",
        "        \n",
        "    def forward(self, x):\n",
        "     \n",
        "        x_pad = torch.nn.functional.pad(x, (self.shift, self.shift, self.shift, self.shift))\n",
        "        # if self.is_mean:\n",
        "        #     x_pad = x_pad.mean(dim=1, keepdim = True)\n",
        "        \n",
        "        \"\"\" 4 cardinal directions \"\"\"\n",
        "        #############################\n",
        "        # x_l2 = x_pad[:, :, self.shift:-self.shift, :-self.shift*2]\n",
        "        # x_r2 = x_pad[:, :, self.shift:-self.shift, self.shift*2:]\n",
        "        # x_t2 = x_pad[:, :, :-self.shift*2, self.shift:-self.shift]\n",
        "        # x_b2 = x_pad[:, :, self.shift*2:, self.shift:-self.shift]\n",
        "        # x_cat = torch.cat([x, x_l2, x_r2, x_t2, x_b2], dim=1) \n",
        "        #############################\n",
        "        \n",
        "        \"\"\" 4 diagonal directions \"\"\"\n",
        "        # #############################\n",
        "        x_lu = x_pad[:, :, :-self.shift*2, :-self.shift*2]\n",
        "        x_ru = x_pad[:, :, :-self.shift*2, self.shift*2:]\n",
        "        x_lb = x_pad[:, :, self.shift*2:, :-self.shift*2]\n",
        "        x_rb = x_pad[:, :, self.shift*2:, self.shift*2:]\n",
        "        x_cat = torch.cat([x, x_lu, x_ru, x_lb, x_rb], dim=1) \n",
        "        # #############################\n",
        "        \n",
        "        \"\"\" 8 cardinal directions \"\"\"\n",
        "        #############################\n",
        "        # x_l2 = x_pad[:, :, self.shift:-self.shift, :-self.shift*2]\n",
        "        # x_r2 = x_pad[:, :, self.shift:-self.shift, self.shift*2:]\n",
        "        # x_t2 = x_pad[:, :, :-self.shift*2, self.shift:-self.shift]\n",
        "        # x_b2 = x_pad[:, :, self.shift*2:, self.shift:-self.shift]\n",
        "        # x_lu = x_pad[:, :, :-self.shift*2, :-self.shift*2]\n",
        "        # x_ru = x_pad[:, :, :-self.shift*2, self.shift*2:]\n",
        "        # x_lb = x_pad[:, :, self.shift*2:, :-self.shift*2]\n",
        "        # x_rb = x_pad[:, :, self.shift*2:, self.shift*2:]\n",
        "        # x_cat = torch.cat([x, x_l2, x_r2, x_t2, x_b2, x_lu, x_ru, x_lb, x_rb], dim=1) \n",
        "        #############################\n",
        "        \n",
        "        # out = self.out(x_cat)\n",
        "        out = x_cat\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "_i4s6IuqtAtW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1LkM7xYjrfW-"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------\n",
        "# Swin Transformer\n",
        "# Copyright (c) 2021 Microsoft\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Ze Liu\n",
        "# --------------------------------------------------------\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "from timm.models.layers import to_2tuple, trunc_normal_\n",
        "# from utils.drop_path import DropPath\n",
        "import torch\n",
        "from einops.layers.torch import Rearrange\n",
        "# from .SPT import ShiftedPatchTokenization\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def window_partition(x, window_size):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: (B, H, W, C)\n",
        "        window_size (int): window size\n",
        "    Returns:\n",
        "        windows: (num_windows*B, window_size, window_size, C)\n",
        "    \"\"\"\n",
        "    B, H, W, C = x.shape\n",
        "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
        "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse(windows, window_size, H, W):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        windows: (num_windows*B, window_size, window_size, C)\n",
        "        window_size (int): Window size\n",
        "        H (int): Height of image\n",
        "        W (int): Width of image\n",
        "    Returns:\n",
        "        x: (B, H, W, C)\n",
        "    \"\"\"\n",
        "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
        "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
        "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
        "    return x\n",
        "\n",
        "\n",
        "class WindowAttention(nn.Module):\n",
        "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
        "    It supports both of shifted and non-shifted window.\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        window_size (tuple[int]): The height and width of the window.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
        "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
        "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0., is_LSA=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size  # Wh, Ww\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "        self.is_LSA = is_LSA\n",
        "        if is_LSA:\n",
        "            self.scale = nn.Parameter(self.scale*torch.ones(self.num_heads))\n",
        "            self.mask = torch.eye((window_size[0]**2), (window_size[0]**2))\n",
        "            self.mask = torch.nonzero((self.mask == 1), as_tuple=False)\n",
        "            self.inf = float('-inf')\n",
        "\n",
        "        # define a parameter table of relative position bias\n",
        "        self.relative_position_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
        "\n",
        "        # get pair-wise relative position index for each token inside the window\n",
        "        coords_h = torch.arange(self.window_size[0])\n",
        "        coords_w = torch.arange(self.window_size[1])\n",
        "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
        "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
        "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
        "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input features with shape of (num_windows*B, N, C)\n",
        "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
        "        \"\"\"\n",
        "        B_, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "\n",
        "        if not self.is_LSA:\n",
        "            q = q * self.scale\n",
        "        \n",
        "        else:\n",
        "            scale = self.scale\n",
        "            q = torch.mul(q, scale.unsqueeze(0).unsqueeze(-1).unsqueeze(-1).expand((B_, self.num_heads, 1, 1)))\n",
        "\n",
        "        \n",
        "        attn = (q @ k.transpose(-2, -1))\n",
        "\n",
        "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
        "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
        "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
        "        attn = attn + relative_position_bias.unsqueeze(0)\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
        "            attn = attn.view(-1, self.num_heads, N, N)\n",
        "\n",
        "            if self.is_LSA:\n",
        "                attn[:, :, self.mask[:, 0], self.mask[:, 1]] = self.inf\n",
        "            attn = self.softmax(attn)\n",
        "            \n",
        "        else:\n",
        "            if self.is_LSA:\n",
        "                attn[:, :, self.mask[:, 0], self.mask[:, 1]] = self.inf\n",
        "            attn = self.softmax(attn)\n",
        "\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
        "\n",
        "\n",
        "class SwinTransformerBlock(nn.Module):\n",
        "    r\"\"\" Swin Transformer Block.\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        input_resolution (tuple[int]): Input resulotion.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        window_size (int): Window size.\n",
        "        shift_size (int): Shift size for SW-MSA.\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
        "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
        "        drop (float, optional): Dropout rate. Default: 0.0\n",
        "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
        "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
        "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
        "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
        "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
        "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, is_LSA=False):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.input_resolution = input_resolution\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        if min(self.input_resolution) <= self.window_size:\n",
        "            # if window size is larger than input resolution, we don't partition windows\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.input_resolution)\n",
        "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
        "\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = WindowAttention(\n",
        "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop, is_LSA=is_LSA)\n",
        "\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "        if self.shift_size > 0:\n",
        "            # calculate attention mask for SW-MSA\n",
        "            H, W = self.input_resolution\n",
        "            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            cnt = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    img_mask[:, h, w, :] = cnt\n",
        "                    cnt += 1\n",
        "\n",
        "            mask_windows = window_partition(img_mask, self.window_size)  # N_w^2, window_size, window_size, 1\n",
        "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)   # N_w^2, window_size, window_size\n",
        "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)   # (N_w^2, 1, window_size, window_size) - (N_w^2, window_size, 1, window_size)\n",
        "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
        "        else:\n",
        "            attn_mask = None\n",
        "\n",
        "        self.register_buffer(\"attn_mask\", attn_mask)    # No parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        # H, W = self.input_resolution\n",
        "        B, L, C = x.shape\n",
        "        H = int(math.sqrt(L))\n",
        "#        assert L == H * W, \"input feature has wrong size\"\n",
        "#        print(H, W, B, L, C)\n",
        "\n",
        "        \n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = x.view(B, H, H, C)\n",
        "\n",
        "        # cyclic shift\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
        "        else:\n",
        "            shifted_x = x\n",
        "\n",
        "        # partition windows\n",
        "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
        "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
        "\n",
        "        # W-MSA/SW-MSA\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n",
        "\n",
        "        # merge windows\n",
        "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, H, H)  # B H' W' C\n",
        "\n",
        "        # reverse cyclic shift\n",
        "        if self.shift_size > 0:\n",
        "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = x.view(B, L, C)\n",
        "\n",
        "        # FFN\n",
        "        x = shortcut + self.drop_path(x)\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
        "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
        "\n",
        "\n",
        "\n",
        "class PatchMerging(nn.Module):\n",
        "    r\"\"\" Patch Merging Layer.\n",
        "    Args:\n",
        "        input_resolution (tuple[int]): Resolution of input feature.\n",
        "        dim (int): Number of input channels.\n",
        "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.input_resolution = input_resolution\n",
        "        self.dim = dim\n",
        "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
        "        self.norm = norm_layer(4 * dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: B, H*W, C\n",
        "        \"\"\"\n",
        "        H, W = self.input_resolution\n",
        "        B, L, C = x.shape\n",
        "#       assert L == H * W, \"input feature has wrong size\"\n",
        "#       assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
        "\n",
        "        x = x.view(B, H, W, C)\n",
        "\n",
        "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
        "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
        "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
        "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
        "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
        "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"input_resolution={self.input_resolution}, dim={self.dim}\"\n",
        "\n",
        "    def flops(self):\n",
        "        H, W = self.input_resolution\n",
        "        flops = H * W * self.dim    # layer norm\n",
        "        flops += (H // 2) * (W // 2) * 4 * self.dim * 2 * self.dim  # reduction\n",
        "        return flops\n",
        "\n",
        "\n",
        "class BasicLayer(nn.Module):\n",
        "    \"\"\" A basic Swin Transformer layer for one stage.\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        input_resolution (tuple[int]): Input resolution.\n",
        "        depth (int): Number of blocks.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        window_size (int): Local window size.\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
        "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
        "        drop (float, optional): Dropout rate. Default: 0.0\n",
        "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
        "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
        "        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n",
        "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
        "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, input_resolution, depth, num_heads, window_size, \n",
        "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=False, use_checkpoint=False,\n",
        "                 is_LSA=False, is_SPT=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.input_resolution = input_resolution\n",
        "        self.depth = depth\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "\n",
        "        \n",
        "        # build blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
        "                                 num_heads=num_heads, window_size=window_size,\n",
        "                                 shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
        "                                 mlp_ratio=mlp_ratio,\n",
        "                                 qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                                 drop=drop, attn_drop=attn_drop,\n",
        "                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
        "                                 norm_layer=norm_layer, is_LSA=is_LSA)\n",
        "            for i in range(depth)])\n",
        "\n",
        "        # patch merging layer\n",
        "        if downsample:\n",
        "            if not is_SPT:\n",
        "                self.downsample = PatchMerging(input_resolution, dim=dim, norm_layer=norm_layer)\n",
        "            else:\n",
        "                self.downsample = ShiftedPatchTokenization(dim, dim*2, 2)\n",
        "                    \n",
        "        else:\n",
        "            self.downsample = None\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        for blk in self.blocks:\n",
        "            if self.use_checkpoint:\n",
        "                x = checkpoint.checkpoint(blk, x)\n",
        "            else:\n",
        "                #print(x.shape)\n",
        "                x = blk(x)\n",
        "        if self.downsample is not None:\n",
        "             x = self.downsample(x)\n",
        "            \n",
        "             \n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
        "\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    r\"\"\" Image to Patch Embedding\n",
        "    Args:\n",
        "        img_size (int): Image size.  Default: 224.\n",
        "        patch_size (int): Patch token size. Default: 4.\n",
        "        in_chans (int): Number of input image channels. Default: 3.\n",
        "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
        "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n",
        "        super().__init__()\n",
        "        img_size = to_2tuple(img_size)\n",
        "        patch_size = to_2tuple(patch_size)\n",
        "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.patches_resolution = patches_resolution\n",
        "\n",
        "        self.in_chans = in_chans\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        if norm_layer is not None:\n",
        "            self.norm = norm_layer(embed_dim)\n",
        "        else:\n",
        "            self.norm = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        # FIXME look at relaxing size constraints\n",
        "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
        "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2)  # B Ph*Pw C\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "        return x\n",
        "\n",
        "class SwinTransformer(nn.Module):\n",
        "    r\"\"\" Swin Transformer\n",
        "        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n",
        "          https://arxiv.org/pdf/2103.14030\n",
        "    Args:\n",
        "        img_size (int | tuple(int)): Input image size. Default 224\n",
        "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
        "        in_chans (int): Number of input image channels. Default: 3\n",
        "        num_classes (int): Number of classes for classification head. Default: 1000\n",
        "        embed_dim (int): Patch embedding dimension. Default: 96\n",
        "        depths (tuple(int)): Depth of each Swin Transformer layer.\n",
        "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
        "        window_size (int): Window size. Default: 7\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
        "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None\n",
        "        drop_rate (float): Dropout rate. Default: 0\n",
        "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
        "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
        "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
        "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
        "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
        "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_size=224, patch_size=4, in_chans=3, num_classes=1000,\n",
        "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
        "                 window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
        "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
        "                 norm_layer=nn.LayerNorm, patch_norm=True,\n",
        "                 use_checkpoint=False, is_LSA=False, is_SPT=False,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "           \n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = len(depths)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.patch_norm = patch_norm\n",
        "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        \n",
        "        \"\"\" Base \"\"\"\n",
        "        if not is_SPT:\n",
        "            self.patch_embed = PatchEmbed(\n",
        "                img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
        "                norm_layer=norm_layer if self.patch_norm else None)     \n",
        "            self.img_resolution = self.patch_embed.patches_resolution\n",
        "\n",
        "        else:\n",
        "            self.patch_embed = ShiftedPatchTokenization(3, embed_dim, patch_size, is_pe=True)\n",
        "            self.img_resolution = (img_size//patch_size, img_size//patch_size)  \n",
        "        \n",
        "        # absolute position embedding\n",
        "        self.absolute_pos_embed = nn.Parameter(torch.zeros(1, self.img_resolution[0]**2, embed_dim))\n",
        "        trunc_normal_(self.absolute_pos_embed, std=.02)\n",
        "\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "\n",
        "        # stochastic depth\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
        "\n",
        "        self.pool_idx = list()\n",
        "        \n",
        "\n",
        "        # build layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i_layer in range(self.num_layers):\n",
        "            is_first = i_layer == 0\n",
        "            layer = BasicLayer(\n",
        "                               dim=int(embed_dim * 2 ** i_layer),\n",
        "                               input_resolution=(self.img_resolution[0] // (2 ** i_layer),\n",
        "                                                 self.img_resolution[1] // (2 ** i_layer)),\n",
        "                               depth=depths[i_layer],\n",
        "                               num_heads=num_heads[i_layer],\n",
        "                               window_size=window_size,\n",
        "                               mlp_ratio=self.mlp_ratio,\n",
        "                               qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                               drop=drop_rate, attn_drop=attn_drop_rate,\n",
        "                               drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
        "                               norm_layer=norm_layer, is_LSA=is_LSA, is_SPT=is_SPT,\n",
        "                               downsample=True if (i_layer < self.num_layers - 1) else False,\n",
        "                               use_checkpoint=use_checkpoint)\n",
        "            self.layers.append(layer)\n",
        "            \n",
        "        self.img_resolution = [self.img_resolution[0] // (2**(self.num_layers-1)), \n",
        "                               self.img_resolution[1] // (2**(self.num_layers-1))]\n",
        "\n",
        "        self.norm = norm_layer(self.num_features)\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "    \n",
        "    def forward_features(self, x):\n",
        "    \n",
        "        k = 0        \n",
        "        \n",
        "        x = self.patch_embed(x)   \n",
        "        \n",
        "        x = x + self.absolute_pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "        \n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "\n",
        "                \n",
        "        x = self.norm(x)  # B L C\n",
        "        x = self.avgpool(x.transpose(1, 2))  # B C 1\n",
        "        x = torch.flatten(x, 1)\n",
        "               \n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(img_size, n_classes, args):\n",
        "    if args.model =='swin':\n",
        "        depths = [2, 6, 4]\n",
        "        num_heads = [3, 6, 12]\n",
        "        mlp_ratio = 2\n",
        "        window_size = 4\n",
        "        patch_size = 2 if img_size == 32 else 4\n",
        "            \n",
        "        model = SwinTransformer(img_size=img_size, window_size=window_size, drop_path_rate=args.sd, \n",
        "                                patch_size=patch_size, mlp_ratio=mlp_ratio, depths=depths, num_heads=num_heads, num_classes=n_classes, \n",
        "                                is_SPT=args.is_SPT, is_LSA=args.is_LSA)\n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "EW-rkUbwsYw4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easydict\n",
        "def init_parser(data_path='./dataset', dataset='CIFAR10', workers=4, print_freq=1, epochs=100, warmup=10):\n",
        "    args = easydict.EasyDict({'data_path':data_path, 'dataset':dataset, 'workers':workers, \\\n",
        "                              'print_freq':print_freq, 'epochs':epochs, 'warmup':warmup, \\\n",
        "                              'batch_size':128, 'lr':0.001, 'weight_decay':5e-2, 'model':'swin', \\\n",
        "                              'disable_cos':False, 'enable_aug':False, 'gpu':0, 'no_cuda':False, \\\n",
        "                              'ls':False, 'seed':0, 'tag':'', 'sd':0.1, 'resume':False,\\\n",
        "                              'smoothing':0.1, 'beta':1.0, 'alpha':1.0, 'mix_prob':0.5, \\\n",
        "                              'ra':3, 're':0.25, 're_sh':0.4, 're_r1':0.3, 'is_LSA':True, 'is_SPT':True, \\\n",
        "                              'cm':False, 'mu':False, 'aa':False\n",
        "                              })\n",
        "\n",
        "    # Optimization hyperparams\n",
        "    # parser.add_argument('--channel', type=int, help='disable cuda')\n",
        "    # parser.add_argument('--heads', type=int, help='disable cuda')\n",
        "    # parser.add_argument('--depth', type=int, help='disable cuda')\n",
        "\n",
        "    return args\n"
      ],
      "metadata": {
        "id": "ogvjqgYluKDn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "\n",
        "from torchvision.transforms import *\n",
        "\n",
        "import random\n",
        "import math\n",
        "\n",
        "class RandomErasing(object):\n",
        "    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
        "        self.EPSILON = probability\n",
        "        self.mean = mean\n",
        "        self.sl = sl\n",
        "        self.sh = sh\n",
        "        self.r1 = r1\n",
        "       \n",
        "    def __call__(self, img):\n",
        "\n",
        "        if random.uniform(0, 1) > self.EPSILON:\n",
        "            return img\n",
        "\n",
        "        for _ in range(100):\n",
        "            area = img.size()[1] * img.size()[2]\n",
        "       \n",
        "            target_area = random.uniform(self.sl, self.sh) * area\n",
        "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
        "\n",
        "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
        "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
        "\n",
        "            if w < img.size()[2] and h < img.size()[1]:\n",
        "                x1 = random.randint(0, img.size()[1] - h)\n",
        "                y1 = random.randint(0, img.size()[2] - w)\n",
        "                if img.size()[0] == 3:\n",
        "                    #img[0, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
        "                    #img[1, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
        "                    #img[2, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
        "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
        "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
        "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
        "                    #img[:, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(3, h, w))\n",
        "                else:\n",
        "                    img[0, x1:x1+h, y1:y1+w] = self.mean[1]\n",
        "                    # img[0, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(1, h, w))\n",
        "                return img\n",
        "\n",
        "        return img"
      ],
      "metadata": {
        "id": "C6DkpJ6Uengc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch, scheduler,  args):\n",
        "    model.train()\n",
        "    loss_val, acc1_val = 0, 0\n",
        "    n = 0\n",
        "        \n",
        "    \n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        if (not args.no_cuda) and torch.cuda.is_available():\n",
        "            images = images.cuda(args.gpu, non_blocking=True)\n",
        "            target = target.cuda(args.gpu, non_blocking=True)\n",
        "                \n",
        "        # Cutmix only\n",
        "        if args.cm and not args.mu:\n",
        "            r = np.random.rand(1)\n",
        "            if r < args.mix_prob:\n",
        "                slicing_idx, y_a, y_b, lam, sliced = cutmix_data(images, target, args)\n",
        "                images[:, :, slicing_idx[0]:slicing_idx[2], slicing_idx[1]:slicing_idx[3]] = sliced\n",
        "                output = model(images)\n",
        "                \n",
        "                loss =  mixup_criterion(criterion, output, y_a, y_b, lam)\n",
        "                \n",
        "                   \n",
        "            else:\n",
        "                output = model(images)\n",
        "                \n",
        "                loss = criterion(output, target)\n",
        "                               \n",
        "                \n",
        "        # Mixup only\n",
        "        elif not args.cm and args.mu:\n",
        "            r = np.random.rand(1)\n",
        "            if r < args.mix_prob:\n",
        "                images, y_a, y_b, lam = mixup_data(images, target, args)\n",
        "                output = model(images)\n",
        "                \n",
        "                loss =  mixup_criterion(criterion, output, y_a, y_b, lam)\n",
        "                \n",
        "                \n",
        "            \n",
        "            else:\n",
        "                output = model(images)\n",
        "                \n",
        "                loss =  criterion(output, target)\n",
        "                 \n",
        "                \n",
        "        # Both Cutmix and Mixup\n",
        "        elif args.cm and args.mu:\n",
        "            r = np.random.rand(1)\n",
        "            if r < args.mix_prob:\n",
        "                switching_prob = np.random.rand(1)\n",
        "                \n",
        "                # Cutmix\n",
        "                if switching_prob < 0.5:\n",
        "                    slicing_idx, y_a, y_b, lam, sliced = cutmix_data(images, target, args)\n",
        "                    images[:, :, slicing_idx[0]:slicing_idx[2], slicing_idx[1]:slicing_idx[3]] = sliced\n",
        "                    output = model(images)\n",
        "                    \n",
        "                    loss =  mixup_criterion(criterion, output, y_a, y_b, lam)\n",
        "                    \n",
        "                    \n",
        "                # Mixup\n",
        "                else:\n",
        "                    images, y_a, y_b, lam = mixup_data(images, target, args)\n",
        "                    output = model(images)\n",
        "                    \n",
        "                    loss = mixup_criterion(criterion, output, y_a, y_b, lam) \n",
        "                    \n",
        "            else:\n",
        "                output = model(images)\n",
        "                \n",
        "                loss = criterion(output, target) \n",
        "          \n",
        "        # No Mix\n",
        "        else:\n",
        "            output = model(images)\n",
        "                                \n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "        acc = accuracy(output, target, (1,))\n",
        "        acc1 = acc[0]\n",
        "        n += images.size(0)\n",
        "        loss_val += float(loss.item() * images.size(0))\n",
        "        acc1_val += float(acc1[0] * images.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        if args.print_freq >= 0 and i % args.print_freq == 0:\n",
        "            avg_loss, avg_acc1 = (loss_val / n), (acc1_val / n)\n",
        "            progress_bar(i, len(train_loader),f'[Epoch {epoch+1}/{args.epochs}][T][{i}]   Loss: {avg_loss:.4e}   Top-1: {avg_acc1:6.2f}   LR: {lr:.7f}'+' '*10)\n",
        "\n",
        "    logger_dict.update(keys[0], avg_loss)\n",
        "    logger_dict.update(keys[1], avg_acc1)\n",
        "    writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
        "    writer.add_scalar(\"Acc/train\", avg_acc1, epoch)\n",
        "    \n",
        "    return lr\n"
      ],
      "metadata": {
        "id": "IFMkF23JfMua"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, model, criterion, lr, args, epoch=None):\n",
        "    model.eval()\n",
        "    loss_val, acc1_val = 0, 0\n",
        "    n = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            if (not args.no_cuda) and torch.cuda.is_available():\n",
        "                images = images.cuda(args.gpu, non_blocking=True)\n",
        "                target = target.cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "            \n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            acc = accuracy(output, target, (1, 5))\n",
        "            acc1 = acc[0]\n",
        "            n += images.size(0)\n",
        "            loss_val += float(loss.item() * images.size(0))\n",
        "            acc1_val += float(acc1[0] * images.size(0))\n",
        "\n",
        "            if args.print_freq >= 0 and i % args.print_freq == 0:\n",
        "                avg_loss, avg_acc1 = (loss_val / n), (acc1_val / n)\n",
        "                progress_bar(i, len(val_loader), f'[Epoch {epoch+1}][V][{i}]   Loss: {avg_loss:.4e}   Top-1: {avg_acc1:6.2f}   LR: {lr:.6f}')\n",
        "    print()        \n",
        "\n",
        "    print(Fore.BLUE)\n",
        "    print('*'*80)\n",
        "    \n",
        "    logger_dict.update(keys[2], avg_loss)\n",
        "    logger_dict.update(keys[3], avg_acc1)\n",
        "    \n",
        "    writer.add_scalar(\"Loss/val\", avg_loss, epoch)\n",
        "    writer.add_scalar(\"Acc/val\", avg_acc1, epoch)\n",
        "\n",
        "    \n",
        "    return avg_acc1"
      ],
      "metadata": {
        "id": "7WX-JkGwh8hK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = init_parser(epochs=50)\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed_all(args.seed)  # if you are using multi-GPU.\n",
        "np.random.seed(args.seed)  # Numpy module.\n",
        "random.seed(args.seed)  # Python random module.\n",
        "torch.manual_seed(args.seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "model_name = args.model\n",
        "best_acc1 = 0\n",
        "\n",
        "if not args.is_SPT:\n",
        "    model_name += \"-Base\"\n",
        "else:\n",
        "    model_name += \"-SPT\"\n",
        "\n",
        "if args.is_LSA:\n",
        "    model_name += \"-LSA\"\n",
        "    \n",
        "model_name += f\"-{args.tag}-{args.dataset}-LR[{args.lr}]-Seed{args.seed}\"\n",
        "writer = SummaryWriter(os.path.join(os.getcwd(), 'tensorboard', model_name))\n",
        "save_path = os.path.join(os.getcwd(), 'save', model_name)\n",
        "if save_path:\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "torch.cuda.set_device(args.gpu)\n",
        "\n",
        "log_dir = os.path.join(save_path, 'history.csv')\n",
        "logger = log.getLogger(__name__)\n",
        "formatter = log.Formatter('%(message)s')\n",
        "streamHandler = log.StreamHandler()\n",
        "fileHandler = log.FileHandler(log_dir, 'a')\n",
        "streamHandler.setFormatter(formatter)\n",
        "fileHandler.setFormatter(formatter)\n",
        "logger.addHandler(streamHandler)\n",
        "logger.addHandler(fileHandler)\n",
        "logger.setLevel(level=log.DEBUG)\n",
        "\n",
        "\n",
        "global logger_dict\n",
        "global keys\n",
        "\n",
        "logger_dict = Logger_dict(logger, save_path)\n",
        "keys = ['T Loss', 'T Top-1', 'V Loss', 'V Top-1']\n",
        "\n",
        "data_info = datainfo(logger, args)\n",
        "\n",
        "model = create_model(data_info['img_size'], data_info['n_classes'], args)\n",
        "model.cuda(args.gpu)\n",
        "\n",
        "print(Fore.GREEN+'*'*80)\n",
        "logger.debug(f\"Creating model: {model_name}\")    \n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "logger.debug(f'Number of params: {format(n_parameters, \",\")}')\n",
        "logger.debug(f'Initial learning rate: {args.lr:.6f}')\n",
        "logger.debug(f\"Start training for {args.epochs} epochs\")\n",
        "print('*'*80+Style.RESET_ALL)\n",
        "\n",
        "\n",
        "if args.ls:\n",
        "    print(Fore.YELLOW + '*'*80)\n",
        "    logger.debug('label smoothing used')\n",
        "    print('*'*80+Style.RESET_ALL)\n",
        "    criterion = LabelSmoothingCrossEntropy()\n",
        "\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()    \n",
        "    \n",
        "if args.sd > 0.:\n",
        "    print(Fore.YELLOW + '*'*80)\n",
        "    logger.debug(f'Stochastic depth({args.sd}) used ')\n",
        "    print('*'*80+Style.RESET_ALL)         \n",
        "\n",
        "criterion = criterion.cuda(args.gpu)\n",
        "\n",
        "normalize = [transforms.Normalize(mean=data_info['stat'][0], std=data_info['stat'][1])]\n",
        "\n",
        "\n",
        "if args.cm:\n",
        "    print(Fore.YELLOW+'*'*80)\n",
        "    logger.debug('Cutmix used')\n",
        "    print('*'*80 + Style.RESET_ALL)\n",
        "if args.mu:\n",
        "    print(Fore.YELLOW+'*'*80)\n",
        "    logger.debug('Mixup used')\n",
        "    print('*'*80 + Style.RESET_ALL)\n",
        "if args.ra > 1:        \n",
        "    \n",
        "    print(Fore.YELLOW+'*'*80)\n",
        "    logger.debug(f'Repeated Aug({args.ra}) used')\n",
        "    print('*'*80 + Style.RESET_ALL)\n",
        "\n",
        "'''\n",
        "    Data Augmentation\n",
        "'''\n",
        "augmentations = []\n",
        "\n",
        "if args.aa == True:\n",
        "    print(Fore.YELLOW+'*'*80)\n",
        "    logger.debug('Autoaugmentation used')      \n",
        "    \n",
        "    if 'CIFAR' in args.dataset:\n",
        "        print(\"CIFAR Policy\")\n",
        "        from utils.autoaug import CIFAR10Policy\n",
        "        augmentations += [\n",
        "            \n",
        "            transforms.RandomCrop(data_info['img_size'], padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            CIFAR10Policy()\n",
        "        ]\n",
        "        \n",
        "    elif 'SVHN' in args.dataset:\n",
        "        print(\"SVHN Policy\")    \n",
        "        from utils.autoaug import SVHNPolicy\n",
        "        augmentations += [\n",
        "            \n",
        "          transforms.RandomCrop(data_info['img_size'], padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            SVHNPolicy()\n",
        "        ]\n",
        "                \n",
        "    else:\n",
        "        from utils.autoaug import ImageNetPolicy\n",
        "        augmentations += [                \n",
        "          transforms.RandomCrop(data_info['img_size'], padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            ImageNetPolicy()\n",
        "        ]\n",
        "        \n",
        "    print('*'*80 + Style.RESET_ALL)\n",
        "    \n",
        "\n",
        "if args.re > 0:\n",
        "    print(Fore.YELLOW + '*'*80)\n",
        "    logger.debug(f'Random erasing({args.re}) used ')\n",
        "    print('*'*80+Style.RESET_ALL)    \n",
        "    \n",
        "    \n",
        "    augmentations += [                \n",
        "        transforms.ToTensor(),\n",
        "        *normalize,\n",
        "        RandomErasing(probability = args.re, sh = args.re_sh, r1 = args.re_r1, mean=data_info['stat'][0])]\n",
        "\n",
        "else:\n",
        "    augmentations += [                \n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(data_info['img_size'], padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        *normalize]\n",
        "\n",
        "\n",
        "augmentations = transforms.Compose(augmentations)\n",
        "  \n",
        "train_dataset, val_dataset = dataload(args, augmentations, normalize, data_info)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,  num_workers=args.workers, pin_memory=True,\n",
        "    batch_sampler=RASampler(len(train_dataset), args.batch_size, 1, args.ra, shuffle=True, drop_last=True))\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=args.workers)\n",
        "'''\n",
        "    Training\n",
        "'''\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "scheduler = build_scheduler(args, optimizer, len(train_loader))\n",
        "\n",
        "summary(model, (3, data_info['img_size'], data_info['img_size']))\n",
        "\n",
        "print()\n",
        "print(\"Beginning training\")\n",
        "print()\n",
        "\n",
        "lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "if args.resume:\n",
        "    checkpoint = torch.load(args.resume)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    final_epoch = args.epochs\n",
        "    args.epochs = final_epoch - (checkpoint['epoch'] + 1)\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(args.epochs)):\n",
        "    lr = train(train_loader, model, criterion, optimizer, epoch, scheduler, args)\n",
        "    acc1 = validate(val_loader, model, criterion, lr, args, epoch=epoch)\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(), \n",
        "        }, \n",
        "        os.path.join(save_path, 'checkpoint.pth'))\n",
        "    \n",
        "    logger_dict.print()\n",
        "    \n",
        "    if acc1 > best_acc1:\n",
        "        print('* Best model upate *')\n",
        "        best_acc1 = acc1\n",
        "        \n",
        "        torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),\n",
        "            }, os.path.join(save_path, 'best.pth'))         \n",
        "    \n",
        "    print(f'Best acc1 {best_acc1:.2f}')\n",
        "    print('*'*80)\n",
        "    print(Style.RESET_ALL)        \n",
        "    \n",
        "    writer.add_scalar(\"Learning Rate\", lr, epoch)\n",
        "    \n",
        "    \n",
        "print(Fore.RED+'*'*80)\n",
        "logger.debug(f'best top-1: {best_acc1:.2f}, final top-1: {acc1:.2f}')\n",
        "print('*'*80+Style.RESET_ALL)\n",
        "torch.save(model.state_dict(), os.path.join(save_path, 'checkpoint.pth'))"
      ],
      "metadata": {
        "id": "cyjWrjzkruyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbf72a2-3127-458d-b2b1-052380bac4f1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CIFAR10\n",
            "CIFAR10\n",
            "CIFAR10\n",
            "CIFAR10\n",
            "CIFAR10\n",
            "CIFAR10\n",
            "CIFAR10\n",
            "CIFAR10\n",
            "Creating model: swin-SPT-LSA--CIFAR10-LR[0.001]-Seed0\n",
            "Creating model: swin-SPT-LSA--CIFAR10-LR[0.001]-Seed0\n",
            "Creating model: swin-SPT-LSA--CIFAR10-LR[0.001]-Seed0\n",
            "Creating model: swin-SPT-LSA--CIFAR10-LR[0.001]-Seed0\n",
            "Creating model: swin-SPT-LSA--CIFAR10-LR[0.001]-Seed0\n",
            "Creating model: swin-SPT-LSA--CIFAR10-LR[0.001]-Seed0\n",
            "Creating model: swin-SPT-LSA--CIFAR10-LR[0.001]-Seed0\n",
            "Creating model: swin-SPT-LSA--CIFAR10-LR[0.001]-Seed0\n",
            "Number of params: 8,562,166\n",
            "Number of params: 8,562,166\n",
            "Number of params: 8,562,166\n",
            "Number of params: 8,562,166\n",
            "Number of params: 8,562,166\n",
            "Number of params: 8,562,166\n",
            "Number of params: 8,562,166\n",
            "Number of params: 8,562,166\n",
            "Initial learning rate: 0.001000\n",
            "Initial learning rate: 0.001000\n",
            "Initial learning rate: 0.001000\n",
            "Initial learning rate: 0.001000\n",
            "Initial learning rate: 0.001000\n",
            "Initial learning rate: 0.001000\n",
            "Initial learning rate: 0.001000\n",
            "Initial learning rate: 0.001000\n",
            "Start training for 50 epochs\n",
            "Start training for 50 epochs\n",
            "Start training for 50 epochs\n",
            "Start training for 50 epochs\n",
            "Start training for 50 epochs\n",
            "Start training for 50 epochs\n",
            "Start training for 50 epochs\n",
            "Start training for 50 epochs\n",
            "Stochastic depth(0.1) used \n",
            "Stochastic depth(0.1) used \n",
            "Stochastic depth(0.1) used \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m********************************************************************************\n",
            "********************************************************************************\u001b[0m\n",
            "\u001b[32m********************************************************************************\n",
            "********************************************************************************\u001b[0m\n",
            "\u001b[33m********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stochastic depth(0.1) used \n",
            "Stochastic depth(0.1) used \n",
            "Stochastic depth(0.1) used \n",
            "Stochastic depth(0.1) used \n",
            "Stochastic depth(0.1) used \n",
            "Repeated Aug(3) used\n",
            "Repeated Aug(3) used\n",
            "Repeated Aug(3) used\n",
            "Repeated Aug(3) used\n",
            "Repeated Aug(3) used\n",
            "Repeated Aug(3) used\n",
            "Repeated Aug(3) used\n",
            "Repeated Aug(3) used\n",
            "Random erasing(0.25) used \n",
            "Random erasing(0.25) used \n",
            "Random erasing(0.25) used \n",
            "Random erasing(0.25) used \n",
            "Random erasing(0.25) used \n",
            "Random erasing(0.25) used \n",
            "Random erasing(0.25) used \n",
            "Random erasing(0.25) used \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************\u001b[0m\n",
            "\u001b[33m********************************************************************************\n",
            "********************************************************************************\u001b[0m\n",
            "\u001b[33m********************************************************************************\n",
            "********************************************************************************\u001b[0m\n",
            "Files already downloaded and verified\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "     PatchShifting-1           [-1, 15, 32, 32]               0\n",
            "         Rearrange-2              [-1, 256, 60]               0\n",
            "         LayerNorm-3              [-1, 256, 60]             120\n",
            "            Linear-4              [-1, 256, 96]           5,856\n",
            "ShiftedPatchTokenization-5              [-1, 256, 96]               0\n",
            "           Dropout-6              [-1, 256, 96]               0\n",
            "         LayerNorm-7              [-1, 256, 96]             192\n",
            "            Linear-8              [-1, 16, 288]          27,936\n",
            "           Softmax-9            [-1, 3, 16, 16]               0\n",
            "          Dropout-10            [-1, 3, 16, 16]               0\n",
            "           Linear-11               [-1, 16, 96]           9,312\n",
            "          Dropout-12               [-1, 16, 96]               0\n",
            "  WindowAttention-13               [-1, 16, 96]               0\n",
            "         Identity-14              [-1, 256, 96]               0\n",
            "        LayerNorm-15              [-1, 256, 96]             192\n",
            "           Linear-16             [-1, 256, 192]          18,624\n",
            "             GELU-17             [-1, 256, 192]               0\n",
            "          Dropout-18             [-1, 256, 192]               0\n",
            "           Linear-19              [-1, 256, 96]          18,528\n",
            "          Dropout-20              [-1, 256, 96]               0\n",
            "              Mlp-21              [-1, 256, 96]               0\n",
            "         Identity-22              [-1, 256, 96]               0\n",
            "SwinTransformerBlock-23              [-1, 256, 96]               0\n",
            "        LayerNorm-24              [-1, 256, 96]             192\n",
            "           Linear-25              [-1, 16, 288]          27,936\n",
            "          Softmax-26            [-1, 3, 16, 16]               0\n",
            "          Dropout-27            [-1, 3, 16, 16]               0\n",
            "           Linear-28               [-1, 16, 96]           9,312\n",
            "          Dropout-29               [-1, 16, 96]               0\n",
            "  WindowAttention-30               [-1, 16, 96]               0\n",
            "         DropPath-31              [-1, 256, 96]               0\n",
            "        LayerNorm-32              [-1, 256, 96]             192\n",
            "           Linear-33             [-1, 256, 192]          18,624\n",
            "             GELU-34             [-1, 256, 192]               0\n",
            "          Dropout-35             [-1, 256, 192]               0\n",
            "           Linear-36              [-1, 256, 96]          18,528\n",
            "          Dropout-37              [-1, 256, 96]               0\n",
            "              Mlp-38              [-1, 256, 96]               0\n",
            "         DropPath-39              [-1, 256, 96]               0\n",
            "SwinTransformerBlock-40              [-1, 256, 96]               0\n",
            "    PatchShifting-41          [-1, 480, 16, 16]               0\n",
            "        Rearrange-42             [-1, 64, 1920]               0\n",
            "        LayerNorm-43             [-1, 64, 1920]           3,840\n",
            "           Linear-44              [-1, 64, 192]         368,832\n",
            "ShiftedPatchTokenization-45              [-1, 64, 192]               0\n",
            "       BasicLayer-46              [-1, 64, 192]               0\n",
            "        LayerNorm-47              [-1, 64, 192]             384\n",
            "           Linear-48              [-1, 16, 576]         111,168\n",
            "          Softmax-49            [-1, 6, 16, 16]               0\n",
            "          Dropout-50            [-1, 6, 16, 16]               0\n",
            "           Linear-51              [-1, 16, 192]          37,056\n",
            "          Dropout-52              [-1, 16, 192]               0\n",
            "  WindowAttention-53              [-1, 16, 192]               0\n",
            "         DropPath-54              [-1, 64, 192]               0\n",
            "        LayerNorm-55              [-1, 64, 192]             384\n",
            "           Linear-56              [-1, 64, 384]          74,112\n",
            "             GELU-57              [-1, 64, 384]               0\n",
            "          Dropout-58              [-1, 64, 384]               0\n",
            "           Linear-59              [-1, 64, 192]          73,920\n",
            "          Dropout-60              [-1, 64, 192]               0\n",
            "              Mlp-61              [-1, 64, 192]               0\n",
            "         DropPath-62              [-1, 64, 192]               0\n",
            "SwinTransformerBlock-63              [-1, 64, 192]               0\n",
            "        LayerNorm-64              [-1, 64, 192]             384\n",
            "           Linear-65              [-1, 16, 576]         111,168\n",
            "          Softmax-66            [-1, 6, 16, 16]               0\n",
            "          Dropout-67            [-1, 6, 16, 16]               0\n",
            "           Linear-68              [-1, 16, 192]          37,056\n",
            "          Dropout-69              [-1, 16, 192]               0\n",
            "  WindowAttention-70              [-1, 16, 192]               0\n",
            "         DropPath-71              [-1, 64, 192]               0\n",
            "        LayerNorm-72              [-1, 64, 192]             384\n",
            "           Linear-73              [-1, 64, 384]          74,112\n",
            "             GELU-74              [-1, 64, 384]               0\n",
            "          Dropout-75              [-1, 64, 384]               0\n",
            "           Linear-76              [-1, 64, 192]          73,920\n",
            "          Dropout-77              [-1, 64, 192]               0\n",
            "              Mlp-78              [-1, 64, 192]               0\n",
            "         DropPath-79              [-1, 64, 192]               0\n",
            "SwinTransformerBlock-80              [-1, 64, 192]               0\n",
            "        LayerNorm-81              [-1, 64, 192]             384\n",
            "           Linear-82              [-1, 16, 576]         111,168\n",
            "          Softmax-83            [-1, 6, 16, 16]               0\n",
            "          Dropout-84            [-1, 6, 16, 16]               0\n",
            "           Linear-85              [-1, 16, 192]          37,056\n",
            "          Dropout-86              [-1, 16, 192]               0\n",
            "  WindowAttention-87              [-1, 16, 192]               0\n",
            "         DropPath-88              [-1, 64, 192]               0\n",
            "        LayerNorm-89              [-1, 64, 192]             384\n",
            "           Linear-90              [-1, 64, 384]          74,112\n",
            "             GELU-91              [-1, 64, 384]               0\n",
            "          Dropout-92              [-1, 64, 384]               0\n",
            "           Linear-93              [-1, 64, 192]          73,920\n",
            "          Dropout-94              [-1, 64, 192]               0\n",
            "              Mlp-95              [-1, 64, 192]               0\n",
            "         DropPath-96              [-1, 64, 192]               0\n",
            "SwinTransformerBlock-97              [-1, 64, 192]               0\n",
            "        LayerNorm-98              [-1, 64, 192]             384\n",
            "           Linear-99              [-1, 16, 576]         111,168\n",
            "         Softmax-100            [-1, 6, 16, 16]               0\n",
            "         Dropout-101            [-1, 6, 16, 16]               0\n",
            "          Linear-102              [-1, 16, 192]          37,056\n",
            "         Dropout-103              [-1, 16, 192]               0\n",
            " WindowAttention-104              [-1, 16, 192]               0\n",
            "        DropPath-105              [-1, 64, 192]               0\n",
            "       LayerNorm-106              [-1, 64, 192]             384\n",
            "          Linear-107              [-1, 64, 384]          74,112\n",
            "            GELU-108              [-1, 64, 384]               0\n",
            "         Dropout-109              [-1, 64, 384]               0\n",
            "          Linear-110              [-1, 64, 192]          73,920\n",
            "         Dropout-111              [-1, 64, 192]               0\n",
            "             Mlp-112              [-1, 64, 192]               0\n",
            "        DropPath-113              [-1, 64, 192]               0\n",
            "SwinTransformerBlock-114              [-1, 64, 192]               0\n",
            "       LayerNorm-115              [-1, 64, 192]             384\n",
            "          Linear-116              [-1, 16, 576]         111,168\n",
            "         Softmax-117            [-1, 6, 16, 16]               0\n",
            "         Dropout-118            [-1, 6, 16, 16]               0\n",
            "          Linear-119              [-1, 16, 192]          37,056\n",
            "         Dropout-120              [-1, 16, 192]               0\n",
            " WindowAttention-121              [-1, 16, 192]               0\n",
            "        DropPath-122              [-1, 64, 192]               0\n",
            "       LayerNorm-123              [-1, 64, 192]             384\n",
            "          Linear-124              [-1, 64, 384]          74,112\n",
            "            GELU-125              [-1, 64, 384]               0\n",
            "         Dropout-126              [-1, 64, 384]               0\n",
            "          Linear-127              [-1, 64, 192]          73,920\n",
            "         Dropout-128              [-1, 64, 192]               0\n",
            "             Mlp-129              [-1, 64, 192]               0\n",
            "        DropPath-130              [-1, 64, 192]               0\n",
            "SwinTransformerBlock-131              [-1, 64, 192]               0\n",
            "       LayerNorm-132              [-1, 64, 192]             384\n",
            "          Linear-133              [-1, 16, 576]         111,168\n",
            "         Softmax-134            [-1, 6, 16, 16]               0\n",
            "         Dropout-135            [-1, 6, 16, 16]               0\n",
            "          Linear-136              [-1, 16, 192]          37,056\n",
            "         Dropout-137              [-1, 16, 192]               0\n",
            " WindowAttention-138              [-1, 16, 192]               0\n",
            "        DropPath-139              [-1, 64, 192]               0\n",
            "       LayerNorm-140              [-1, 64, 192]             384\n",
            "          Linear-141              [-1, 64, 384]          74,112\n",
            "            GELU-142              [-1, 64, 384]               0\n",
            "         Dropout-143              [-1, 64, 384]               0\n",
            "          Linear-144              [-1, 64, 192]          73,920\n",
            "         Dropout-145              [-1, 64, 192]               0\n",
            "             Mlp-146              [-1, 64, 192]               0\n",
            "        DropPath-147              [-1, 64, 192]               0\n",
            "SwinTransformerBlock-148              [-1, 64, 192]               0\n",
            "   PatchShifting-149            [-1, 960, 8, 8]               0\n",
            "       Rearrange-150             [-1, 16, 3840]               0\n",
            "       LayerNorm-151             [-1, 16, 3840]           7,680\n",
            "          Linear-152              [-1, 16, 384]       1,474,944\n",
            "ShiftedPatchTokenization-153              [-1, 16, 384]               0\n",
            "      BasicLayer-154              [-1, 16, 384]               0\n",
            "       LayerNorm-155              [-1, 16, 384]             768\n",
            "          Linear-156             [-1, 16, 1152]         443,520\n",
            "         Softmax-157           [-1, 12, 16, 16]               0\n",
            "         Dropout-158           [-1, 12, 16, 16]               0\n",
            "          Linear-159              [-1, 16, 384]         147,840\n",
            "         Dropout-160              [-1, 16, 384]               0\n",
            " WindowAttention-161              [-1, 16, 384]               0\n",
            "        DropPath-162              [-1, 16, 384]               0\n",
            "       LayerNorm-163              [-1, 16, 384]             768\n",
            "          Linear-164              [-1, 16, 768]         295,680\n",
            "            GELU-165              [-1, 16, 768]               0\n",
            "         Dropout-166              [-1, 16, 768]               0\n",
            "          Linear-167              [-1, 16, 384]         295,296\n",
            "         Dropout-168              [-1, 16, 384]               0\n",
            "             Mlp-169              [-1, 16, 384]               0\n",
            "        DropPath-170              [-1, 16, 384]               0\n",
            "SwinTransformerBlock-171              [-1, 16, 384]               0\n",
            "       LayerNorm-172              [-1, 16, 384]             768\n",
            "          Linear-173             [-1, 16, 1152]         443,520\n",
            "         Softmax-174           [-1, 12, 16, 16]               0\n",
            "         Dropout-175           [-1, 12, 16, 16]               0\n",
            "          Linear-176              [-1, 16, 384]         147,840\n",
            "         Dropout-177              [-1, 16, 384]               0\n",
            " WindowAttention-178              [-1, 16, 384]               0\n",
            "        DropPath-179              [-1, 16, 384]               0\n",
            "       LayerNorm-180              [-1, 16, 384]             768\n",
            "          Linear-181              [-1, 16, 768]         295,680\n",
            "            GELU-182              [-1, 16, 768]               0\n",
            "         Dropout-183              [-1, 16, 768]               0\n",
            "          Linear-184              [-1, 16, 384]         295,296\n",
            "         Dropout-185              [-1, 16, 384]               0\n",
            "             Mlp-186              [-1, 16, 384]               0\n",
            "        DropPath-187              [-1, 16, 384]               0\n",
            "SwinTransformerBlock-188              [-1, 16, 384]               0\n",
            "       LayerNorm-189              [-1, 16, 384]             768\n",
            "          Linear-190             [-1, 16, 1152]         443,520\n",
            "         Softmax-191           [-1, 12, 16, 16]               0\n",
            "         Dropout-192           [-1, 12, 16, 16]               0\n",
            "          Linear-193              [-1, 16, 384]         147,840\n",
            "         Dropout-194              [-1, 16, 384]               0\n",
            " WindowAttention-195              [-1, 16, 384]               0\n",
            "        DropPath-196              [-1, 16, 384]               0\n",
            "       LayerNorm-197              [-1, 16, 384]             768\n",
            "          Linear-198              [-1, 16, 768]         295,680\n",
            "            GELU-199              [-1, 16, 768]               0\n",
            "         Dropout-200              [-1, 16, 768]               0\n",
            "          Linear-201              [-1, 16, 384]         295,296\n",
            "         Dropout-202              [-1, 16, 384]               0\n",
            "             Mlp-203              [-1, 16, 384]               0\n",
            "        DropPath-204              [-1, 16, 384]               0\n",
            "SwinTransformerBlock-205              [-1, 16, 384]               0\n",
            "       LayerNorm-206              [-1, 16, 384]             768\n",
            "          Linear-207             [-1, 16, 1152]         443,520\n",
            "         Softmax-208           [-1, 12, 16, 16]               0\n",
            "         Dropout-209           [-1, 12, 16, 16]               0\n",
            "          Linear-210              [-1, 16, 384]         147,840\n",
            "         Dropout-211              [-1, 16, 384]               0\n",
            " WindowAttention-212              [-1, 16, 384]               0\n",
            "        DropPath-213              [-1, 16, 384]               0\n",
            "       LayerNorm-214              [-1, 16, 384]             768\n",
            "          Linear-215              [-1, 16, 768]         295,680\n",
            "            GELU-216              [-1, 16, 768]               0\n",
            "         Dropout-217              [-1, 16, 768]               0\n",
            "          Linear-218              [-1, 16, 384]         295,296\n",
            "         Dropout-219              [-1, 16, 384]               0\n",
            "             Mlp-220              [-1, 16, 384]               0\n",
            "        DropPath-221              [-1, 16, 384]               0\n",
            "SwinTransformerBlock-222              [-1, 16, 384]               0\n",
            "      BasicLayer-223              [-1, 16, 384]               0\n",
            "       LayerNorm-224              [-1, 16, 384]             768\n",
            "AdaptiveAvgPool1d-225               [-1, 384, 1]               0\n",
            "          Linear-226                   [-1, 10]           3,850\n",
            "================================================================\n",
            "Total params: 8,533,090\n",
            "Trainable params: 8,533,090\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 23.86\n",
            "Params size (MB): 32.55\n",
            "Estimated Total Size (MB): 56.43\n",
            "----------------------------------------------------------------\n",
            "\n",
            "Beginning training\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50][T][1170]   Loss: 1.5751e+00   Top-1:  43.11   LR: 0.0001009          \n",
            "[Epoch 1][V][78]   Loss: 1.2404e+00   Top-1:  55.42   LR: 0.000101\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t1.5751214263583737\n",
            "T Top-1\t43.11285760034159\n",
            "V Loss\t1.2403974447250365\n",
            "V Top-1\t55.42\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [03:15<2:39:51, 195.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 55.42\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 2/50][T][1170]   Loss: 1.0347e+00   Top-1:  63.11   LR: 0.0002008          \n",
            "[Epoch 2][V][78]   Loss: 9.1944e-01   Top-1:  67.05   LR: 0.000201\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t1.0346717726563308\n",
            "T Top-1\t63.113791631084545\n",
            "V Loss\t0.9194403228759765\n",
            "V Top-1\t67.05\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [06:31<2:36:42, 195.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 67.05\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 3/50][T][1170]   Loss: 7.2815e-01   Top-1:  74.33   LR: 0.0003007          \n",
            "[Epoch 3][V][78]   Loss: 8.5674e-01   Top-1:  70.91   LR: 0.000301\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.7281523625327418\n",
            "T Top-1\t74.32883219470538\n",
            "V Loss\t0.8567358511924744\n",
            "V Top-1\t70.91\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [09:47<2:33:22, 195.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 70.91\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 4/50][T][1170]   Loss: 5.4348e-01   Top-1:  80.76   LR: 0.0004006          \n",
            "[Epoch 4][V][78]   Loss: 8.0762e-01   Top-1:  73.84   LR: 0.000401\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.5434779106654437\n",
            "T Top-1\t80.76363684884714\n",
            "V Loss\t0.8076164762496948\n",
            "V Top-1\t73.84\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [13:03<2:30:05, 195.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 73.84\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 5/50][T][1170]   Loss: 4.4301e-01   Top-1:  84.38   LR: 0.0005005          \n",
            "[Epoch 5][V][78]   Loss: 7.8685e-01   Top-1:  75.10   LR: 0.000501\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.4430058037211608\n",
            "T Top-1\t84.38300597779676\n",
            "V Loss\t0.7868496666908265\n",
            "V Top-1\t75.1\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [16:19<2:26:51, 195.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 75.10\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 6/50][T][1170]   Loss: 3.7996e-01   Top-1:  86.61   LR: 0.0006004          \n",
            "[Epoch 6][V][78]   Loss: 7.8576e-01   Top-1:  75.92   LR: 0.000600\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.3799643236841532\n",
            "T Top-1\t86.6106692997438\n",
            "V Loss\t0.7857618550300598\n",
            "V Top-1\t75.92\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [19:35<2:23:38, 195.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 75.92\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 7/50][T][1170]   Loss: 3.3991e-01   Top-1:  88.09   LR: 0.0007003          \n",
            "[Epoch 7][V][78]   Loss: 7.5987e-01   Top-1:  76.47   LR: 0.000700\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.3399131581072722\n",
            "T Top-1\t88.0851035439795\n",
            "V Loss\t0.7598741766929626\n",
            "V Top-1\t76.47\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [22:51<2:20:36, 196.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 76.47\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 8/50][T][1170]   Loss: 3.0053e-01   Top-1:  89.48   LR: 0.0008002          \n",
            "[Epoch 8][V][78]   Loss: 8.3968e-01   Top-1:  76.30   LR: 0.000800\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [26:08<2:17:25, 196.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.30052570488389796\n",
            "T Top-1\t89.48147950469684\n",
            "V Loss\t0.8396818264007568\n",
            "V Top-1\t76.3\n",
            "\n",
            "Best acc1 76.47\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 9/50][T][1170]   Loss: 2.8188e-01   Top-1:  90.14   LR: 0.0009001          \n",
            "[Epoch 9][V][78]   Loss: 8.0244e-01   Top-1:  77.42   LR: 0.000900\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.28187640494866617\n",
            "T Top-1\t90.14063834329633\n",
            "V Loss\t0.802444375705719\n",
            "V Top-1\t77.42\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [29:25<2:14:23, 196.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 77.42\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 10/50][T][1170]   Loss: 2.5950e-01   Top-1:  90.95   LR: 0.0010000          \n",
            "[Epoch 10][V][78]   Loss: 8.1955e-01   Top-1:  76.83   LR: 0.001000\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [32:41<2:10:58, 196.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.25949996101561007\n",
            "T Top-1\t90.95391225448334\n",
            "V Loss\t0.8195484823226928\n",
            "V Top-1\t76.83\n",
            "\n",
            "Best acc1 77.42\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 11/50][T][1170]   Loss: 2.3225e-01   Top-1:  91.90   LR: 0.0009985          \n",
            "[Epoch 11][V][78]   Loss: 8.3621e-01   Top-1:  78.21   LR: 0.000998\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.2322549119680789\n",
            "T Top-1\t91.9032877882152\n",
            "V Loss\t0.8362138164520264\n",
            "V Top-1\t78.21\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [35:58<2:07:48, 196.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 78.21\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 12/50][T][1170]   Loss: 2.0431e-01   Top-1:  92.95   LR: 0.0009939          \n",
            "[Epoch 12][V][78]   Loss: 8.0516e-01   Top-1:  79.18   LR: 0.000994\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.20431010228487084\n",
            "T Top-1\t92.9534052092229\n",
            "V Loss\t0.8051638414382934\n",
            "V Top-1\t79.18\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [39:15<2:04:26, 196.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 79.18\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 13/50][T][1170]   Loss: 1.7753e-01   Top-1:  93.82   LR: 0.0009862          \n",
            "[Epoch 13][V][78]   Loss: 8.3982e-01   Top-1:  79.45   LR: 0.000986\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.17752519815231266\n",
            "T Top-1\t93.81871797608882\n",
            "V Loss\t0.8398152425289154\n",
            "V Top-1\t79.45\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [42:31<2:01:06, 196.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 79.45\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 14/50][T][1170]   Loss: 1.6219e-01   Top-1:  94.41   LR: 0.0009756          \n",
            "[Epoch 14][V][78]   Loss: 8.0275e-01   Top-1:  79.71   LR: 0.000976\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.16219010728353317\n",
            "T Top-1\t94.41449615713066\n",
            "V Loss\t0.8027450355529785\n",
            "V Top-1\t79.71\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [45:46<1:57:37, 196.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 79.71\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 15/50][T][1170]   Loss: 1.4751e-01   Top-1:  94.89   LR: 0.0009620          \n",
            "[Epoch 15][V][78]   Loss: 8.3898e-01   Top-1:  79.32   LR: 0.000962\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [49:02<1:54:20, 196.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.14751232905197256\n",
            "T Top-1\t94.89018467122118\n",
            "V Loss\t0.8389796092987061\n",
            "V Top-1\t79.32\n",
            "\n",
            "Best acc1 79.71\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 16/50][T][1170]   Loss: 1.3645e-01   Top-1:  95.29   LR: 0.0009456          \n",
            "[Epoch 16][V][78]   Loss: 8.4559e-01   Top-1:  80.43   LR: 0.000946\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.13644599856651307\n",
            "T Top-1\t95.28648057216054\n",
            "V Loss\t0.8455919489860535\n",
            "V Top-1\t80.43\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [52:18<1:51:04, 196.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 80.43\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 17/50][T][1170]   Loss: 1.2511e-01   Top-1:  95.64   LR: 0.0009264          \n",
            "[Epoch 17][V][78]   Loss: 8.7760e-01   Top-1:  80.12   LR: 0.000926\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [55:33<1:47:42, 195.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.12511115925375413\n",
            "T Top-1\t95.64274658411614\n",
            "V Loss\t0.8775976937055587\n",
            "V Top-1\t80.12\n",
            "\n",
            "Best acc1 80.43\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 18/50][T][1170]   Loss: 1.1924e-01   Top-1:  95.92   LR: 0.0009046          \n",
            "[Epoch 18][V][78]   Loss: 8.2483e-01   Top-1:  81.00   LR: 0.000905\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.11923522895709457\n",
            "T Top-1\t95.92028714773697\n",
            "V Loss\t0.8248301813602448\n",
            "V Top-1\t81.0\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [58:49<1:44:22, 195.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 81.00\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 19/50][T][1170]   Loss: 1.0725e-01   Top-1:  96.32   LR: 0.0008803          \n",
            "[Epoch 19][V][78]   Loss: 8.3510e-01   Top-1:  81.32   LR: 0.000880\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.10725101610179592\n",
            "T Top-1\t96.31658304867635\n",
            "V Loss\t0.8351039840698242\n",
            "V Top-1\t81.32\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:02:05<1:41:11, 195.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 81.32\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 20/50][T][1170]   Loss: 1.0257e-01   Top-1:  96.46   LR: 0.0008537          \n",
            "[Epoch 20][V][78]   Loss: 8.7195e-01   Top-1:  79.76   LR: 0.000854\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:05:21<1:37:56, 195.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.1025734158045112\n",
            "T Top-1\t96.45935631938514\n",
            "V Loss\t0.8719472801208497\n",
            "V Top-1\t79.76\n",
            "\n",
            "Best acc1 81.32\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 21/50][T][1170]   Loss: 9.6317e-02   Top-1:  96.70   LR: 0.0008249          \n",
            "[Epoch 21][V][78]   Loss: 8.1789e-01   Top-1:  81.88   LR: 0.000825\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.09631675768589536\n",
            "T Top-1\t96.70020281810419\n",
            "V Loss\t0.8178937817573547\n",
            "V Top-1\t81.88\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:08:38<1:34:47, 196.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 81.88\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 22/50][T][1170]   Loss: 8.7536e-02   Top-1:  97.00   LR: 0.0007941          \n",
            "[Epoch 22][V][78]   Loss: 8.3012e-01   Top-1:  82.10   LR: 0.000794\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.08753557986222736\n",
            "T Top-1\t96.9984254910333\n",
            "V Loss\t0.8301187068939209\n",
            "V Top-1\t82.1\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:11:54<1:31:33, 196.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 82.10\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 23/50][T][1170]   Loss: 8.3180e-02   Top-1:  97.15   LR: 0.0007615          \n",
            "[Epoch 23][V][78]   Loss: 8.5118e-01   Top-1:  81.18   LR: 0.000761\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:15:10<1:28:17, 196.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.08317957479064532\n",
            "T Top-1\t97.15187339880444\n",
            "V Loss\t0.8511788854599\n",
            "V Top-1\t81.18\n",
            "\n",
            "Best acc1 82.10\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 24/50][T][1170]   Loss: 7.8228e-02   Top-1:  97.35   LR: 0.0007273          \n",
            "[Epoch 24][V][78]   Loss: 8.6806e-01   Top-1:  81.56   LR: 0.000727\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:18:27<1:25:03, 196.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.07822835396889384\n",
            "T Top-1\t97.34535119555935\n",
            "V Loss\t0.868059076499939\n",
            "V Top-1\t81.56\n",
            "\n",
            "Best acc1 82.10\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 25/50][T][1170]   Loss: 7.2416e-02   Top-1:  97.53   LR: 0.0006917          \n",
            "[Epoch 25][V][78]   Loss: 8.8393e-01   Top-1:  82.00   LR: 0.000692\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:21:43<1:21:47, 196.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.07241597971031928\n",
            "T Top-1\t97.53415883859948\n",
            "V Loss\t0.8839295742988587\n",
            "V Top-1\t82.0\n",
            "\n",
            "Best acc1 82.10\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 26/50][T][1170]   Loss: 6.8475e-02   Top-1:  97.66   LR: 0.0006549          \n",
            "[Epoch 26][V][78]   Loss: 8.9025e-01   Top-1:  82.15   LR: 0.000655\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.06847528055275255\n",
            "T Top-1\t97.66492314261315\n",
            "V Loss\t0.8902476426124573\n",
            "V Top-1\t82.15\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:24:59<1:18:31, 196.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 82.15\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 27/50][T][1170]   Loss: 6.3984e-02   Top-1:  97.81   LR: 0.0006171          \n",
            "[Epoch 27][V][78]   Loss: 8.8684e-01   Top-1:  81.11   LR: 0.000617\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:28:16<1:15:14, 196.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.06398353419114734\n",
            "T Top-1\t97.81436806148591\n",
            "V Loss\t0.886838108253479\n",
            "V Top-1\t81.11\n",
            "\n",
            "Best acc1 82.15\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 28/50][T][1170]   Loss: 6.0155e-02   Top-1:  97.96   LR: 0.0005786          \n",
            "[Epoch 28][V][78]   Loss: 8.8872e-01   Top-1:  82.21   LR: 0.000579\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.06015491392542978\n",
            "T Top-1\t97.96181148590948\n",
            "V Loss\t0.8887209238529206\n",
            "V Top-1\t82.21\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:31:32<1:12:02, 196.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 82.21\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 29/50][T][1170]   Loss: 5.5933e-02   Top-1:  98.11   LR: 0.0005397          \n",
            "[Epoch 29][V][78]   Loss: 8.6492e-01   Top-1:  82.47   LR: 0.000540\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.055932854198437916\n",
            "T Top-1\t98.11325789923143\n",
            "V Loss\t0.864921402835846\n",
            "V Top-1\t82.47\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:34:50<1:08:53, 196.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 82.47\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 30/50][T][1170]   Loss: 4.9721e-02   Top-1:  98.32   LR: 0.0005005          \n",
            "[Epoch 30][V][78]   Loss: 7.9878e-01   Top-1:  82.88   LR: 0.000501\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.049721016787568365\n",
            "T Top-1\t98.31807749786508\n",
            "V Loss\t0.7987843943595886\n",
            "V Top-1\t82.88\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:38:08<1:05:40, 197.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 82.88\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 31/50][T][1170]   Loss: 4.7319e-02   Top-1:  98.36   LR: 0.0004613          \n",
            "[Epoch 31][V][78]   Loss: 8.6971e-01   Top-1:  82.32   LR: 0.000461\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:41:25<1:02:23, 197.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.04731949617454733\n",
            "T Top-1\t98.36344470538002\n",
            "V Loss\t0.869708578491211\n",
            "V Top-1\t82.32\n",
            "\n",
            "Best acc1 82.88\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 32/50][T][1170]   Loss: 4.5249e-02   Top-1:  98.46   LR: 0.0004224          \n",
            "[Epoch 32][V][78]   Loss: 8.9106e-01   Top-1:  82.86   LR: 0.000422\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:44:42<59:06, 197.01s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.04524936696596406\n",
            "T Top-1\t98.45684777967548\n",
            "V Loss\t0.8910640858650207\n",
            "V Top-1\t82.86\n",
            "\n",
            "Best acc1 82.88\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 33/50][T][1170]   Loss: 3.9929e-02   Top-1:  98.67   LR: 0.0003839          \n",
            "[Epoch 33][V][78]   Loss: 9.5703e-01   Top-1:  82.17   LR: 0.000384\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:47:58<55:48, 196.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.03992925162183957\n",
            "T Top-1\t98.6683390264731\n",
            "V Loss\t0.9570272714614868\n",
            "V Top-1\t82.17\n",
            "\n",
            "Best acc1 82.88\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 34/50][T][1170]   Loss: 3.6033e-02   Top-1:  98.81   LR: 0.0003461          \n",
            "[Epoch 34][V][78]   Loss: 9.4037e-01   Top-1:  82.30   LR: 0.000346\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:51:16<52:32, 197.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.03603274080916057\n",
            "T Top-1\t98.80577497865073\n",
            "V Loss\t0.9403681758880615\n",
            "V Top-1\t82.3\n",
            "\n",
            "Best acc1 82.88\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 35/50][T][1170]   Loss: 3.2748e-02   Top-1:  98.90   LR: 0.0003093          \n",
            "[Epoch 35][V][78]   Loss: 8.7819e-01   Top-1:  83.37   LR: 0.000309\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.03274776446530643\n",
            "T Top-1\t98.8985108881298\n",
            "V Loss\t0.8781851999759674\n",
            "V Top-1\t83.37\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [1:54:34<49:20, 197.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 83.37\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 36/50][T][1170]   Loss: 3.1566e-02   Top-1:  98.90   LR: 0.0002737          \n",
            "[Epoch 36][V][78]   Loss: 8.8928e-01   Top-1:  83.08   LR: 0.000274\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [1:57:51<46:04, 197.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.03156575571644628\n",
            "T Top-1\t98.8991780529462\n",
            "V Loss\t0.8892827708244324\n",
            "V Top-1\t83.08\n",
            "\n",
            "Best acc1 83.37\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 37/50][T][1170]   Loss: 2.8207e-02   Top-1:  99.04   LR: 0.0002395          \n",
            "[Epoch 37][V][78]   Loss: 9.1197e-01   Top-1:  83.49   LR: 0.000240\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.028207453379516287\n",
            "T Top-1\t99.03794833475662\n",
            "V Loss\t0.9119747738838195\n",
            "V Top-1\t83.49\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [2:01:09<42:48, 197.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 83.49\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 38/50][T][1170]   Loss: 2.4040e-02   Top-1:  99.16   LR: 0.0002069          \n",
            "[Epoch 38][V][78]   Loss: 8.8895e-01   Top-1:  83.80   LR: 0.000207\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.024039503738720942\n",
            "T Top-1\t99.16337532023911\n",
            "V Loss\t0.8889488147735596\n",
            "V Top-1\t83.8\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [2:04:27<39:31, 197.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 83.80\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 39/50][T][1170]   Loss: 2.3334e-02   Top-1:  99.19   LR: 0.0001761          \n",
            "[Epoch 39][V][78]   Loss: 9.4361e-01   Top-1:  83.55   LR: 0.000176\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [2:07:44<36:12, 197.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.023334075774981367\n",
            "T Top-1\t99.19339773697695\n",
            "V Loss\t0.9436096293449402\n",
            "V Top-1\t83.55\n",
            "\n",
            "Best acc1 83.80\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 40/50][T][1170]   Loss: 2.0256e-02   Top-1:  99.33   LR: 0.0001473          \n",
            "[Epoch 40][V][78]   Loss: 9.1123e-01   Top-1:  84.03   LR: 0.000147\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.02025614267506519\n",
            "T Top-1\t99.32616353543979\n",
            "V Loss\t0.9112305102348328\n",
            "V Top-1\t84.03\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [2:11:03<32:57, 197.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 84.03\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 41/50][T][1170]   Loss: 1.7446e-02   Top-1:  99.41   LR: 0.0001207          \n",
            "[Epoch 41][V][78]   Loss: 9.0484e-01   Top-1:  84.05   LR: 0.000121\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.01744635159411079\n",
            "T Top-1\t99.41022630230572\n",
            "V Loss\t0.904835481262207\n",
            "V Top-1\t84.05\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [2:14:21<29:41, 197.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 84.05\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 42/50][T][1170]   Loss: 1.5982e-02   Top-1:  99.46   LR: 0.0000964          \n",
            "[Epoch 42][V][78]   Loss: 8.7572e-01   Top-1:  84.44   LR: 0.000096\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.01598197420006254\n",
            "T Top-1\t99.45959649871904\n",
            "V Loss\t0.8757159769058227\n",
            "V Top-1\t84.44\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [2:17:39<26:24, 198.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 84.44\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 43/50][T][1170]   Loss: 1.3670e-02   Top-1:  99.52   LR: 0.0000746          \n",
            "[Epoch 43][V][78]   Loss: 8.8086e-01   Top-1:  84.90   LR: 0.000075\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n",
            "T Loss\t0.013670090946265381\n",
            "T Top-1\t99.51964133219471\n",
            "V Loss\t0.880859190940857\n",
            "V Top-1\t84.9\n",
            "\n",
            "* Best model upate *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [2:20:58<23:07, 198.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best acc1 84.90\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 44/50][T][1170]   Loss: 1.2712e-02   Top-1:  99.58   LR: 0.0000554          \n",
            "[Epoch 44][V][78]   Loss: 8.9581e-01   Top-1:  84.64   LR: 0.000055\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [2:24:17<19:50, 198.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.012711574440279023\n",
            "T Top-1\t99.5750160119556\n",
            "V Loss\t0.895806789970398\n",
            "V Top-1\t84.64\n",
            "\n",
            "Best acc1 84.90\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 45/50][T][1170]   Loss: 1.1603e-02   Top-1:  99.61   LR: 0.0000390          \n",
            "[Epoch 45][V][78]   Loss: 9.1074e-01   Top-1:  84.27   LR: 0.000039\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [2:27:36<16:33, 198.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.01160347413959346\n",
            "T Top-1\t99.61304440649018\n",
            "V Loss\t0.9107387508392334\n",
            "V Top-1\t84.27\n",
            "\n",
            "Best acc1 84.90\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 46/50][T][1170]   Loss: 9.8585e-03   Top-1:  99.67   LR: 0.0000254          \n",
            "[Epoch 46][V][78]   Loss: 9.2343e-01   Top-1:  84.45   LR: 0.000025\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [2:30:54<13:14, 198.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.009858457048498994\n",
            "T Top-1\t99.66775192143467\n",
            "V Loss\t0.9234324228286743\n",
            "V Top-1\t84.45\n",
            "\n",
            "Best acc1 84.90\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 47/50][T][1170]   Loss: 9.5008e-03   Top-1:  99.67   LR: 0.0000148          \n",
            "[Epoch 47][V][78]   Loss: 9.0768e-01   Top-1:  84.90   LR: 0.000015\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [2:34:13<09:55, 198.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.009500830177395352\n",
            "T Top-1\t99.67042058070025\n",
            "V Loss\t0.9076848116874695\n",
            "V Top-1\t84.9\n",
            "\n",
            "Best acc1 84.90\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 48/50][T][1170]   Loss: 9.3981e-03   Top-1:  99.68   LR: 0.0000071          \n",
            "[Epoch 48][V][78]   Loss: 9.0215e-01   Top-1:  84.81   LR: 0.000007\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [2:37:31<06:37, 198.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.00939814007344496\n",
            "T Top-1\t99.67842655849701\n",
            "V Loss\t0.9021532170295715\n",
            "V Top-1\t84.81\n",
            "\n",
            "Best acc1 84.90\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 49/50][T][1170]   Loss: 9.0563e-03   Top-1:  99.69   LR: 0.0000025          \n",
            "[Epoch 49][V][78]   Loss: 9.0026e-01   Top-1:  84.88   LR: 0.000003\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [2:40:50<03:18, 198.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.009056332364848842\n",
            "T Top-1\t99.69310418445772\n",
            "V Loss\t0.900261706829071\n",
            "V Top-1\t84.88\n",
            "\n",
            "Best acc1 84.90\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "[Epoch 50/50][T][1170]   Loss: 8.4135e-03   Top-1:  99.71   LR: 0.0000010          \n",
            "[Epoch 50][V][78]   Loss: 8.9727e-01   Top-1:  84.88   LR: 0.000001\n",
            "\n",
            "\u001b[34m\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:44:10<00:00, 197.00s/it]\n",
            "best top-1: 84.90, final top-1: 84.88\n",
            "best top-1: 84.90, final top-1: 84.88\n",
            "best top-1: 84.90, final top-1: 84.88\n",
            "best top-1: 84.90, final top-1: 84.88\n",
            "best top-1: 84.90, final top-1: 84.88\n",
            "best top-1: 84.90, final top-1: 84.88\n",
            "best top-1: 84.90, final top-1: 84.88\n",
            "best top-1: 84.90, final top-1: 84.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T Loss\t0.008413474368789985\n",
            "T Top-1\t99.71045046968403\n",
            "V Loss\t0.897269169330597\n",
            "V Top-1\t84.88\n",
            "\n",
            "Best acc1 84.90\n",
            "********************************************************************************\n",
            "\u001b[0m\n",
            "\u001b[31m********************************************************************************\n",
            "********************************************************************************\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download model"
      ],
      "metadata": {
        "id": "iKkbY5GYfSJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(os.path.join(save_path, 'checkpoint.pth')) \n",
        "files.download(os.path.join(save_path, 'best.pth')) \n",
        "files.download(os.path.join(save_path, 'log.csv')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DHe1FXP4anGH",
        "outputId": "dd1315d4-cf60-4a4f-9bae-b6566c4e7dd3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4142bafa-079f-4e69-8595-0cea84cdf3cb\", \"checkpoint.pth\", 34375023)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d61a9ef9-2ae9-464a-b9fe-035b8eec859b\", \"best.pth\", 102980235)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e6a0c9b1-5b44-4e61-9c4c-5e336d60c6b6\", \"log.csv\", 3203)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XTO_-Flnfi6C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}